\newcommand{\evolvemf}{\code{evolve\_mf}}



\section{Data}

\ps{TODO: Are we using pulsar data?}

We use a wide range of data to constrain the parameters of our models. In general, for both 47\,Tuc
and NGC\,3201 we use archival kinematic data from ground based spectroscopy, number density profiles from
\emph{Gaia} and stellar mass function data from HST photometry.

\subsection{Kinematics and density profiles}

\subsubsection{Proper motion dispersion profiles}

For 47 Tuc, we use two sets of {\it Hubble Space Telescope} (HST) proper motion data that are not
available for NGC\,3201. To probe the inner regions of the cluster we use the proper motion
dispersion profiles (both tangential and radial components) from \citet{Watkins2015} which are based
on a catalogue of proper motions of bright stars from \citet{Bellini2014}. These dispersion profiles
are built from stars brighter than the main sequence turn-off ($0.85 \ \mathrm{M}_\odot$ and $0.8 \
	\mathrm{M}_\odot$ for 47\,Tuc and NGC\,3201). To probe the kinematics in the outer regions of the
cluster, we also use the data from \citet{Heyl2017}, for which the mean mass of the measured stars
is $0.38 \ \mathrm{M}_{\odot}$. The outer proper motion data also allows us to constrain the amount
of radial anisotropy present in the cluster, which can mimic the effect of central dark mass in
isotropic models by raising the central velocity dispersion \citep{Zocchi2017}.


\subsubsection{Line-of-sight velocity dispersion profiles}

For both 47\,Tuc and NGC\,3201 we use the line-of-sight velocity dispersion profiles from
\citet{Baumgardt2018} to further constrain the kinematics of the clusters. These dispersion profiles
are based on archival ESO/VLT and Keck spectra along with previously published radial velocity data
from the literature. As these radial velocity samples are dominated by bright stars, we assume that
the velocity dispersion profile traces the kinematics of upper main-sequence and evolved stars in
our models.

\subsubsection{Number density profiles}
We use the number density profiles from \citet{DeBoer2019} to constrain the size and structural
parameters of the clusters. These profiles are made up of a combination of cluster members based on
Gaia DR2 data in the outer regions and data from various literature sources in the central regions.
The Gaia data used only includes bright stars ($m > 0.6 \ \mathrm{M}_\odot$, for both clusters) and
the literature data is dominated by bright stars, therefore in our models we assume the profiles
probe the distribution of upper main sequence and evolved stars.

\subsection{Stellar mass functions}

As a constraint on the global present-day stellar mass function of the clusters, we use a
compilation of HST based stellar mass function data from
Baumgardt\footnote{\url{https://people.smp.uq.edu.au/HolgerBaumgardt/globular/}} (2021, priv.
comm.), which represent an updated and augmented version of the stellar mass functions found in
\citet{Sollima2017}. This compilation is made up of several HST fields at varying distances from the
cluster centre. These fields extend out to $14 '$ and $8.33 '$ from the cluster centres for 47\,Tuc
and NGC\,3201 respectively and cover a mass range of $0.16 - 0.8 \ \mathrm{M}_\odot$. The large
radial and mass ranges allow us to constrain the degree mass segregation in the cluster.


\subsection{Binary Data}

\ps{Expand this, if we even need it here, might be better to discuss this when we discuss generating
	the binaries} When creating realistic binary populations we use the data from \citet{Milone2012} to
inform our choices of binary fraction and mass ratio distribution. For NGC\,3201 we have
\citet{Giesers2019} as an additional measurement of the binary population.





\section{Generating mass functions}

The bulk of project deals with generating mass functions to use as inputs to the \code{LIMEPY}
models, we do this in two main steps, we first generate a present day mass function comprised of
only single stars, and we then modify it to include binary stars.

\subsection{Single Star Mass Functions}

\ps{Probably want more details here}

To generate the mass functions comprised of single stars we use the \evolvemf{} algorithm from
\code{SSPTools}\footnote{\url{www.github.com/pjs902/ssptools}}, a publicly available package for
working with simple stellar populations.

The \evolvemf{} algorithm combines precomputed grids of stellar evolution models and isochrones to
accurate model the evolution of the initial mass function, fully including the effects of stellar
evolution, mass loss due to escaping stars and dynamical ejections. The algorithm returns a sampled
mass functions for a requested time, ideal for use in the \code{LIMEPY} models.

We provide to \evolvemf{} the initial mass function slopes and breakpoints, the cluster age,
metallicity and escape velocity, as well as parameters which control the mass loss due to escaping
stars the specific binning to be used when the present day mass function is sampled.



\subsection{Binary Mass Functions}

In order to include binary stars in our mass functions we make use of the assumption that for the
vast majority of their interaction with other objects, binary systems behave essentially as point
masses given the fact that they are tightly bound. This means that in order to replicate the effects
of a binary population in our mass function, we simply need to shift some of the mass in single
stars into heavier bins which act as the "binary bins".


We do this by splitting the process up into several steps. First we divide the total binary fraction
among the values if $q$ in the requested mass ration distribution. We weight the $f_b$ values
assigned to the individual values of $q$ by the chosen mass ration distribution, so a flat mass
ratio distribution would have the total binary fraction divided evenly among the values while a
"solar distribution" (see \citealt{Fisher2005}) would have a significantly higher portion of the
total $f_b$ assigned to equal mass binaries.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{figures/q-dists.png}
	\caption{\ps{TODO: add caption}}
	\label{fig:2/q-dists}
\end{figure}


After we have calculated the individual binary fractions for each value of $q$, we then go through
each bin of main sequence stars and attempt to make binaries. The companion mass for a given bin is
calculated using the current value of $q$ and number of binaries to make is calculated using the
binary fraction for the current value of $q$. After the companion mass and number of binaries are
set, we then find the closest bin to the companion mass and subtract the mass corresponding to the
calculated number of binaries, adding the subtracted mass to a new bin with a mass equal to the sum
of each binary component.


We repeat this process for each bin of main sequence stars until all bins have a binary fraction
equal to that of the current value of $q$. We do this process for each value of q in the mass ratio
distribution, resulting in each main sequence bin having a total binary fraction equal to the
requested total and a mass ratio distribution identical to the requested distribution.


This process tends to create on the order of 150 new bins in our mass function which dramatically
increases the runtime of the \code{LIMEPY} models. In order to prevent this we group together binary
bins of similar masses, forming on the order of 15 binary bins containing binary systems of similar
total mass but differing mass ratios.


\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{figures/shifted-mf.png}
	\caption{\ps{TODO: add caption}}
	\label{fig:2/shifted-mf}
\end{figure}



\section{Fitting Models to Data}


To fit our models to the data we use the \code{GCfit}
package\footnote{\url{www.github.com/nmdickson/gcfit}}. \code{GCfit} provides a uniform interface for
fitting \evolvemf{} and \code{LIMEPY} models to observations of clusters using either MCMC or Nested
Sampling.

\subsection{Likelihoods}

The majority of the likelihood functions we use are simple Gaussian likelihoods of the following form:

\begin{equation}
	\ln \left(\mathcal{L}_{i}\right)=\frac{1}{2}
	\sum_{r}\left(\frac{\left(\sigma_{\mathrm{obs}}(r)
		-\sigma_{\mathrm{model}}(r)\right)^{2}}{\delta \sigma_{\mathrm{obs}}^{2}(r)}
	-\ln \left(\delta \sigma_{\mathrm{obs}}^{2}(r)\right)\right)
\end{equation}

Where $\mathcal{L}$ is the likelihood, $\sigma$ is the line-of-sight velocity dispersion, $r$ is the
projected distance from the cluster centre, and $\delta \sigma$ is the uncertainty in the velocity
dispersion. The likelihoods for other observables are formulated in the same way, and the specifics
are discussed in \code{GCfit}'s documentation\footnote{\url{gcfit.readthedocs.io}}.
\ps{put some more details in?}




\subsection{Fitting Mass Functions to Observations}

When the mass function data is collected, the mass is recorded based on the position of the star on
the CMD with an isochrone fit to the cluster. This means that any binary stars in the sample are
recorded as single stars a mass corresponding to a star with the average colour of the two binary
components and a luminosity corresponding to the sum of the two components.

Additionally, when we move mass around to create binary bins we remove mass from the surface density
profiles which would be compared to the mass function data. In order to compensate for these
effects, we rescale the surface density profiles to include the stars which are in binary bins,
according to how they would have been observed using the observational method described above.

In order to determine the observed mass we use a grid of MIST isochrones computed at a range of
metallicities, at the age of the cluster. We use the isochrone to determine the luminosity of the
binary components and then use the isochrone to determine the observed mass of the combined
luminosities. We then scale the surface density profile of the main sequence bin which most closely
matches the observed mass of the binary system by the total mass of the binary system.